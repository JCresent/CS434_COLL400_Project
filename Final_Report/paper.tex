% TODO fill in your paper title
\newcommand{\PaperTitle}{A Comparative Analysis of Machine Learning Algorithms for Website Traffic Classification from Network Packets }
% TODO fill in your paper number when you get it
\newcommand{\PaperNumber}{XXX}

\documentclass[10pt,sigconf,letterpaper,nonacm]{acmart}

\DeclareMathSizes{12}{30}{16}{12}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is the preamble; include packages as you see fit.
% Here are a few recommendations:
% \usepackage{color}
% \usepackage{graphicx}
% \usepackage[labelformat=simple]{subcaption}
% \usepackage{xspace}
% \usepackage{multirow}
% \usepackage[ruled,vlined]{algorithm2e}
% \usepackage{ulem}
% \normalem

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{\PaperTitle}

\author{Matthew Berthoud, Lake Bradford, Justin Cresent, Will Katabian}
\affiliation{
  \institution{William \& Mary}
  \city{Williamsburg}
  \state{Virginia}
  \country{USA}
}

\begin{abstract}
Accurately Identifying web traffic destination and origins is crucial for the efficiency of a network. This project explores the potential of machine learning in reference to web traffic classification based on the 
analysis of network packets. 
We monitored and analyzed web traffic data from ChatGPT, Blackboard, and Linkedin, with the objective 
of building models which will be able to predict the web traffic origin of a specific packet. The collection of data was performed
using wireshark, then the data was reformatted to eliminate bias and get more accurate results.
Using the collected data we then trained four models which had varying levels of accuracy, Logistic Regression (56\%), 
K-Nearest Neighbors (77\%), Random Forest (78\%), and finally a neural
network (80\%). This project shows the importance of machine learning within the field of 
network traffic analysis as automaton is much more efficient and precise compared to manually
examining web traffic, especially in a scale as large as the internet. One example of our project's significance is that this can be crucial data analysis 
for network administrators and security professionals, whom would examine the network for malicious traffic.

\end{abstract}

\keywords{Network Traffic, Machine Learning, Web Traffic Classification, Network Packets, Data Analysis, Neural Networks, Random Forest, K-Nearest Neighbors, Logistic Regression}

\maketitle

\section{Introduction}
The ability to monitor and analyze network traffic is crucial for the efficiency and security of a network \cite{10.1145/2388576.2388608}. 
It helps to manage the overall network performance, detect and prevent malicious activities, and ensure the network is operating as intended.
The present day internet is composed of a vast variety of diverse web traffic, of which requires a more sophisticated approach to analyze and classify network traffic\cite{10.5555/3432601.3432608}.
This project investigates a variety of machine learning algorithms to see which most accurately and effectively classify web traffic based on data from a set of captured network packets. 

  Traffic classification is very significant in practice, if done accurately and effectively \cite{10.1109/TNET.2014.2320577}. For reasons mentioned previously, the observed capabilities of this and other projects 
  can be crucial for network administrators and security professionals, whom would examine the network for malicious traffic.

  For this project, many sets of packet data were collected from three popular websites: ChatGPT, Blackboard, and Linkedin. These sets were then merged into a single dataset, which was then split into training and testing sets. 
  Four models were then trained and tested on this data: Logistic Regression, K-Nearest Neighbors, Random Forest, and Neural Network \cite{scikit-learn}. 

  A thorough evaluation of the models was conducted through testing and validation sets, hyperparameter optimization employing cross-validation and grid search, and computing accuracy and Macro F1 scores. The results showed that the Neural Network model 
  acheived the highest accuracy of $80\%$ and Macro F1 score of BLANK. %%TODO fill in the score.%%
  These scores display the model's ability to accurately classify the selected websites based on captured network packet data.

  Overall, the significance of this project is seen in its use of Machine Learning and the extensions of these applications into the discipline of network traffic analysis. This practice has potential to be utilized in real-world applications, and many sources
  proving it already is \cite{10.5555/3432601.3432608}. 

\section{Proposed Method}
This section presents the methodology for how this project goes about capturing network packet data, analyzing the data, and classifying it based on its website of origin.

\subsection{Capturing Data}
\subsubsection{Wireshark}

\subsubsection{Data Collection}
To commence the collection of our data, we open Wireshark and select a network connection. 
In this project we established a connection the College of William and Mary's network interface (en0). In order to isolate the web traffic in order to specifically collect 
packets that we are analyzing, the capture filter functionality is utilized. The website of interest is then visited in the web browser which causes Wireshark to begin collecting the packets being exchanged.
After collecting sufficient packets, the data is then converted into a Comma Seperated Values (CSV). This process of data collection is performed for Blackboard, LinkedIn, and ChatGPT resulting in the creation of 
three distinct files. 

\subsection{Data Preparation and Processing}
In order to ensure the integrity and reliability of our models,
the collected data must be processed prior to model training.


\subsubsection{Feature Selection}



\subsubsection{Data Formatting}
To maintain normalized representation in all the collected datasets, a process of data harmonization 
was applied after collecting the necessary data. The dataset with the minimum number of observations is identified and accounted for when
truncating the remaining two datasets. Subsequently, the three datasets are combined and rearranged to minimize bias while training each of our models.
This process ensures a balanced yet unbaised dataset that maximizes the effectivness of our models.


\subsection{Employed models}
\subsubsection{Logistic Regression (Baseline)}

\subsubsection{K-Nearest Neighbors}

\subsubsection{Random Forest}

\subsubsection{Neural Network}
\section{Evaluation}
This section comprehensively evaluates our models and their performance on the dataset and validating sets. Later, goes on to determine the model which best classified our selected websites based on network packet data.
\subsection{Dataset}
\subsection{Evaluation Metrics}
Accuracy and Macro F1 score were the primary metrics used to evaluate each model. These metrics are applicable to all models and allow for
a direct comparison for each of their performances. Two other metrics: precision and recall, help to provide a more detailed understanding of the model's performance on a class-to-class basis.
\newline \\
The equation for \textbf{Accuracy}: \\
\[
Accuracy= \frac{TP + TN}{TS}
\]
\newline \\
The equation for \textbf{Macro F1}: \\
\[
Macro F 1= \frac{1}{n} \sum_{1}^{n} \frac{2*Precision_i*Recall_i}{Precision_i+Recall_i}
\]
\newline \\
The equation for \textbf{Recall}: \\
\[
Recall= \frac{TP}{TP + FN}
\]
\newline \\
The equation for \textbf{Precision}: \\
\[
Accuracy= \frac{TP}{TP + FP}
\]
Accuracy is the score that rates the effectivness of a model at classification overall (ie. how many it predicited correctly out of the total set). 

Macro F1 is the harmonic average of the of precision and recall for every class, and then taking the average of these calculated scores accross all classes.

Recall is the calculation of how many the model correctly classified within a class (ie. how many truly belong in that class in the entire dataset). 
Precision is the calculation of how many the model correctly classified within a class (ie. can be thought of as class accuracy).


\subsection{Model Comparison and Evaluation Results}


\section{Discussion \& Future Work}
\subsection{Analysis of Results}
\subsection{Future Work}

\section{Conclusion}

% Note from the CFP that this section must include a statement about
% ethical issues; papers that do not include such a statement may be
% rejected.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% We're in the endgame now

\bibliographystyle{ACM-Reference-Format}
\bibliography{refs}
\cite{10.1145/2388576.2388608}
\cite{10.5555/3432601.3432608}
\cite{10.1109/TNET.2014.2320577}
\cite{scikit-learn}
\cite{Wireshark}

\end{document}
