% TODO fill in your paper title
\newcommand{\PaperTitle}{A Comparative Analysis of Machine Learning Algorithms for Website Traffic Classification from Network Packets }
% TODO fill in your paper number when you get it
\newcommand{\PaperNumber}{XXX}

\documentclass[10pt,sigconf,letterpaper,nonacm]{acmart}

\DeclareMathSizes{12}{30}{16}{12}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is the preamble; include packages as you see fit.
% Here are a few recommendations:
% \usepackage{color}
\usepackage{graphicx}
% \usepackage[labelformat=simple]{subcaption}
% \usepackage{xspace}
% \usepackage{multirow}
% \usepackage[ruled,vlined]{algorithm2e}
% \usepackage{ulem}
% \normalem

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{\PaperTitle}

\author{Matthew Berthoud, Lake Bradford, Justin Cresent, Will Katabian}
\affiliation{
  \institution{William \& Mary}
  \city{Williamsburg}
  \state{Virginia}
  \country{USA}
}

\begin{abstract}
Accurately Identifying web traffic destination and origins is crucial for the efficiency of a network. This project explores the potential of machine learning in reference to web traffic classification based on the 
analysis of network packets. 
We monitored and analyzed web traffic data from ChatGPT, Blackboard, and Linkedin, with the objective 
of building models which will be able to predict the web traffic origin of a specific packet. The collection of data was performed
using wireshark, then the data was reformatted to eliminate bias and get more accurate results.
Using the collected data we then trained four models which had varying levels of accuracy, Logistic Regression (56\%), 
K-Nearest Neighbors (77\%), Random Forest (78\%), and finally a neural
network (80\%). This project shows the importance of machine learning within the field of 
network traffic analysis as automaton is much more efficient and precise compared to manually
examining web traffic, especially in a scale as large as the internet. One example of our project's significance is that this can be crucial data analysis 
for network administrators and security professionals, whom would examine the network for malicious traffic.

\end{abstract}

\keywords{Network Traffic, Machine Learning, Web Traffic Classification, Network Packets, Data Analysis, Neural Networks, Random Forest, K-Nearest Neighbors, Logistic Regression}

\maketitle

\section{Introduction}
The ability to monitor and analyze network traffic is crucial for the efficiency and security of a network \cite{10.1145/2388576.2388608}. 
It helps to manage the overall network performance, detect and prevent malicious activities, and ensure the network is operating as intended.
The present day internet is composed of a vast variety of diverse web traffic, of which requires a more sophisticated approach to analyze and classify network traffic\cite{10.5555/3432601.3432608}.
This project investigates a variety of machine learning algorithms to see which most accurately and effectively classify web traffic based on data from a set of captured network packets. 

  Traffic classification is very significant in practice, if done accurately and effectively \cite{10.1109/TNET.2014.2320577}. For reasons mentioned previously, the observed capabilities of this and other projects 
  can be crucial for network administrators and security professionals, whom would examine the network for malicious traffic.

  For this project, many sets of packet data were collected from three popular websites: ChatGPT, Blackboard, and Linkedin. These sets were then merged into a single dataset, which was then split into training and testing sets. 
  Four models were then trained and tested on this data: Logistic Regression, K-Nearest Neighbors, Random Forest, and Neural Network \cite{scikit-learn}. 

  A thorough evaluation of the models was conducted through testing and validation sets, hyperparameter optimization employing cross-validation and grid search, and computing accuracy and Macro F1 scores. The results showed that the Neural Network model 
  acheived the highest accuracy of $80\%$ and Macro F1 score of BLANK. %%TODO fill in the score.%%
  These scores display the model's ability to accurately classify the selected websites based on captured network packet data.

  Overall, the significance of this project is seen in its use of Machine Learning and the extensions of these applications into the discipline of network traffic analysis. This practice has potential to be utilized in real-world applications, and many sources
  proving it already is \cite{10.5555/3432601.3432608}. 

\section{Proposed Method}
This section presents the methodology for how this project goes about capturing network packet data, analyzing the data, and classifying it based on its website of origin.

\subsection{Capturing Data}

\begin{figure*}[t]
  \centering
  \includegraphics[width=\textwidth]{Figures_and_Graphs/webCollectionDiagram.png}
  \caption{Wireshark Data Collection Process}
  \label{fig:dataCollection}
\end{figure*}
\begin{figure*}[t]
  \centering
  \includegraphics[width=0.5\textwidth]{Figures_and_Graphs/wiresharkFigure.png}
  \includegraphics[width=0.5\textwidth]{Figures_and_Graphs/wiresharkDataFigure.png}
  \caption{Wireshark interface and example of captured data}
  \label{fig:wireshark}
\end{figure*}
\subsubsection{Network analysis tool} For this project, the tool chosen and used was Wireshark \cite{Wireshark}, a widely used network protocol analyzer. Wireshark is capable of capturing and analyzing network packets, and is able to provide a detailed
 view of the packets exchanged between the client and server. Wireshark offers a broad variety of features that allow for users to capture, decode, and analyze network packets. It shows the packet data in a human-readable format, and provides a detailed view of the packet's contents.
 This data contains information on time taken for packet to send and arrive, protocols used, size of each packet, and other fields such as more information on the packet and the source IP address. This tool also supports use of different forms of link communication and can be specified to capture packets from a specific network interface (ie. Ethernet, Wifi, etc.). 
 The many applications and ease of use of Wireshark make it a great tool for this project.
 
 The process for this project (shown in Figure 1) involved setting a hostname filter for each desired website, capturing packets from the host, and then exporting the data to a CSV file.

 \subsubsection{Data Collection}
To commence the collection of our data, we open Wireshark and select a network connection. 
In this project we established a connection the College of William and Mary's network interface (en0). In order to isolate the web traffic in order to specifically collect 
packets that we are analyzing, the capture filter functionality is utilized. The website of interest is then visited in the web browser which causes Wireshark to begin collecting the packets being exchanged.
After collecting sufficient packets, the data is then converted into a Comma Separated Values (CSV). This process of data collection is performed for Blackboard, LinkedIn, and ChatGPT resulting in the creation of 
three distinct files. 

\subsection{Data Preparation and Processing}
In order to ensure the integrity and reliability of our models,
the collected data must be processed prior to model training.


\subsubsection{Feature Selection}
The data collection process using Wireshark yields a dataset containing seven distinct features shown in Figure 2. 
\begin{itemize}
  \item \textbf{Packet Number}: An integer representing the order in which the packets were captured during the Wireshark session. Provides insight on the order of the packets on the network interface. 
  \item \textbf{Time}: A floating point value representing the relative timestamp for each packet since the start of the Wireshark session. Similar to packet number, the time feature provides a better understanding of the packet order yet is more precise.
  \item \textbf{Source}: A string value containing the internet protocol address of the device that the packet originated from. 
  \item \textbf{Destination}: A string value containing the internet protocol address of the device that is receiving the packet. 
  \item \textbf{Protocol}: A string value which contains the network protocol employed for the transmission of the packet. Three distinct protocols were identified within the datasets used in this project (QUIC, TCP and TLSv1.2).
  \item \textbf{Length}: An integer representing the size of a packet in bits 
  \item \textbf{Info}: A string value containing more information pertaining to a packet. This value can vary heavily between packets.
\end{itemize} 
As the objective of this project is to predict the origin of web traffic, both source and destination are excluded from the dataset used to train the models. 
Similairly, the "info" feature is also removed from our train data as further testing revealed that the feature led to extraneous noise in our dataset. 
Consequently, the features selected for training and testing the models are Time, Length, and Protocol. The Protocol feature is converted to an integer for compatibility with 
the models using a dictionary to map protocol names to a corresponding numerical representation (e.g., 'TCP': 0, 'QUIC': 1, 'TLSv1.2': 2) as shown in Figure 3.  Additionally, a categorical variable titled "Website" 
is created which displays which website the packet originated (e.g., LinkedIn, ChatGPT, Blackboard). The "Website" feature acts as the target variable and allows 
the models to detect relationships between the packets and their corresponding web traffic origin. 

\subsubsection{Data Formatting}
To maintain normalized representation in all the collected datasets, a process of data harmonization 
was applied after collecting the necessary data. The dataset with the minimum number of observations is identified and accounted for when
truncating the remaining two datasets. Subsequently, the three datasets are combined and rearranged to minimize bias while training each of our models.
This process ensures a balanced yet unbiased dataset that maximizes the effectiveness of our models. Figure 3 pesents the refined data following the data preparation. 
\begin{figure}[htp] % h: here, t: top, p: bottom
  \centering
  \includegraphics[width=0.5\textwidth]{Figures_and_Graphs/fullDataDiagram.png}
  \caption{Processed Web Traffic Data}
  \label{fig:wireshark}
\end{figure}




\subsection{Employed models}
\subsubsection{Logistic Regression (Baseline)}

\subsubsection{K-Nearest Neighbors}

\subsubsection{Random Forest}

\subsubsection{Neural Network}
\section{Evaluation}
This section comprehensively evaluates our models and their performance on the dataset and validating sets. Later, goes on to determine the model which best classified our selected websites based on network packet data.
\subsection{Dataset}
\subsection{Evaluation Metrics}
Accuracy and Macro F1 score were the primary metrics used to evaluate each model. These metrics are applicable to all models and allow for
a direct comparison for each of their performances. Two other metrics: precision and recall, help to provide a more detailed understanding of the model's performance on a class-to-class basis.
\newline \\
The equation for \textbf{Accuracy}: \\
\[
Accuracy= \frac{TP + TN}{TS}
\]
\newline \\
The equation for \textbf{Macro F1}: \\
\[
Macro F 1= \frac{1}{n} \sum_{1}^{n} \frac{2*Precision_i*Recall_i}{Precision_i+Recall_i}
\]
\newline \\
The equation for \textbf{Recall}: \\
\[
Recall= \frac{TP}{TP + FN}
\]
\newline \\
The equation for \textbf{Precision}: \\
\[
Accuracy= \frac{TP}{TP + FP}
\]
Accuracy is the score that rates the effectiveness of a model at classification overall (ie. how many it predicted correctly out of the total set). 

Macro F1 is the harmonic average of the of precision and recall for every class, and then taking the average of these calculated scores across all classes.

Recall is the calculation of how many the model correctly classified within a class (ie. how many truly belong in that class in the entire dataset). 
Precision is the calculation of how many the model correctly classified within a class (ie. can be thought of as class accuracy).


\subsection{Model Comparison and Evaluation Results}


\section{Discussion \& Future Work}
\subsection{Analysis of Results}
\subsection{Future Work}

\section{Conclusion}

% Note from the CFP that this section must include a statement about
% ethical issues; papers that do not include such a statement may be
% rejected.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% We're in the endgame now

\bibliographystyle{ACM-Reference-Format}
\bibliography{refs}
\cite{10.1145/2388576.2388608}
\cite{10.5555/3432601.3432608}
\cite{10.1109/TNET.2014.2320577}
\cite{scikit-learn}
\cite{Wireshark}

\end{document}
